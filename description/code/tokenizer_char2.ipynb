{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tfo_QNB47GAI",
        "outputId": "40ef68fc-cdc2-405e-a589-988075d288b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f855594f-ec61-4acf-9b5c-69fe12b5c720\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>사람이 다가오고 있습니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>사람과 자전거가 다가오고 있습니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>자전거와 사람이 다가오고 있습니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>사람과 자전거가 있습니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>자전거와 사람이 있습니다</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f855594f-ec61-4acf-9b5c-69fe12b5c720')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f855594f-ec61-4acf-9b5c-69fe12b5c720 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f855594f-ec61-4acf-9b5c-69fe12b5c720');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             sentence\n",
              "0       사람이 다가오고 있습니다\n",
              "1  사람과 자전거가 다가오고 있습니다\n",
              "2  자전거와 사람이 다가오고 있습니다\n",
              "3       사람과 자전거가 있습니다\n",
              "4       자전거와 사람이 있습니다"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/captionTrain.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S658gnsL7krK"
      },
      "source": [
        "음절 단위"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhxpju1P7gvV",
        "outputId": "54dd666b-9192-4b70-ce4c-0cff7be1b389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "고유 문자수 58개\n"
          ]
        }
      ],
      "source": [
        "vocab = set()\n",
        "for i, row in train.iterrows(): # dataframe의 row별로 반복\n",
        "    sentence = row['sentence']\n",
        "    for token in sentence: #음절 단위 token 반복\n",
        "        if token not in vocab:\n",
        "            vocab.add(token) # token set에 없다면 추가\n",
        "        else:\n",
        "            continue\n",
        "vocab.add('<EOS>') # 문장 마지막을  <EOS>로 끝낼거라 <End of Sequence> token 추가\n",
        "print ('고유 문자수 {}개'.format(len(vocab)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjpJbJqkDmsb",
        "outputId": "578fc53b-78ca-49e4-d355-d721cab5c043"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{' ',\n",
              " ',',\n",
              " '<EOS>',\n",
              " '가',\n",
              " '갑',\n",
              " '개',\n",
              " '거',\n",
              " '걸',\n",
              " '고',\n",
              " '과',\n",
              " '놓',\n",
              " '늘',\n",
              " '니',\n",
              " '다',\n",
              " '대',\n",
              " '동',\n",
              " '되',\n",
              " '두',\n",
              " '둘',\n",
              " '드',\n",
              " '들',\n",
              " '라',\n",
              " '람',\n",
              " '러',\n",
              " '럿',\n",
              " '로',\n",
              " '를',\n",
              " '명',\n",
              " '바',\n",
              " '보',\n",
              " '볼',\n",
              " '사',\n",
              " '서',\n",
              " '설',\n",
              " '세',\n",
              " '수',\n",
              " '습',\n",
              " '앞',\n",
              " '어',\n",
              " '여',\n",
              " '오',\n",
              " '옵',\n",
              " '와',\n",
              " '워',\n",
              " '으',\n",
              " '의',\n",
              " '이',\n",
              " '있',\n",
              " '자',\n",
              " '전',\n",
              " '져',\n",
              " '차',\n",
              " '치',\n",
              " '킥',\n",
              " '타',\n",
              " '탄',\n",
              " '토',\n",
              " '폴'}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZbgSvQBCMv7",
        "outputId": "d6379ec4-17ea-4cc7-ecec-ff748be9708a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{' ': 13,\n",
              " ',': 57,\n",
              " '<EOS>': 14,\n",
              " '가': 3,\n",
              " '갑': 16,\n",
              " '개': 36,\n",
              " '거': 22,\n",
              " '걸': 58,\n",
              " '고': 40,\n",
              " '과': 41,\n",
              " '놓': 19,\n",
              " '늘': 45,\n",
              " '니': 35,\n",
              " '다': 2,\n",
              " '대': 48,\n",
              " '동': 30,\n",
              " '되': 10,\n",
              " '두': 43,\n",
              " '둘': 31,\n",
              " '드': 51,\n",
              " '들': 54,\n",
              " '라': 23,\n",
              " '람': 32,\n",
              " '러': 47,\n",
              " '럿': 55,\n",
              " '로': 8,\n",
              " '를': 9,\n",
              " '명': 18,\n",
              " '바': 15,\n",
              " '보': 52,\n",
              " '볼': 44,\n",
              " '사': 25,\n",
              " '서': 12,\n",
              " '설': 17,\n",
              " '세': 46,\n",
              " '수': 50,\n",
              " '습': 7,\n",
              " '앞': 27,\n",
              " '어': 11,\n",
              " '여': 34,\n",
              " '오': 33,\n",
              " '옵': 1,\n",
              " '와': 5,\n",
              " '워': 39,\n",
              " '으': 49,\n",
              " '의': 21,\n",
              " '이': 53,\n",
              " '있': 38,\n",
              " '자': 24,\n",
              " '전': 4,\n",
              " '져': 29,\n",
              " '차': 28,\n",
              " '치': 37,\n",
              " '킥': 6,\n",
              " '타': 26,\n",
              " '탄': 42,\n",
              " '토': 20,\n",
              " '폴': 56}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab, start=1)}\n",
        "char2idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LzzhUPu8Uq_"
      },
      "source": [
        "음절 단위"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UbByjses8LJq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "sentence2vec_list = []\n",
        "for i, row in train.iterrows():\n",
        "    temp_arr = np.array([char2idx[c] for c in row['sentence']] + [char2idx['<EOS>']])\n",
        "    sentence2vec_list.append(temp_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFjpnkPaGar4",
        "outputId": "18e9e3a4-9cff-4491-a362-f3dbae717caa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([25, 32, 53, 13,  2,  3, 33, 40, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 41, 13, 24,  4, 22,  3, 13,  2,  3, 33, 40, 13, 38,  7, 35,\n",
              "         2, 14]),\n",
              " array([24,  4, 22,  5, 13, 25, 32, 53, 13,  2,  3, 33, 40, 13, 38,  7, 35,\n",
              "         2, 14]),\n",
              " array([25, 32, 41, 13, 24,  4, 22,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  5, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22, 13, 34, 47, 13, 48,  5, 13, 25, 32, 53, 13, 38,  7, 35,\n",
              "         2, 14]),\n",
              " array([25, 32, 53, 13, 34, 55, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 13, 34, 47, 13, 18, 41, 13, 24,  4, 22, 13, 34, 47, 13, 48,\n",
              "         3, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 53, 13, 27, 49,  8, 13, 58, 11,  3, 40, 13, 38,  7, 35,  2,\n",
              "        14]),\n",
              " array([ 4, 30,  6, 52, 51,  9, 13, 42, 13, 25, 32, 53, 13,  2,  3, 33, 40,\n",
              "        13, 38,  7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  9, 13, 42, 13, 25, 32, 41, 13, 34, 47, 13, 18,\n",
              "        21, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  3, 13, 34, 47, 13, 48, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 13, 34, 47, 13, 18, 41, 13,  4, 30,  6, 52, 51,  3, 13, 38,\n",
              "         7, 35,  2, 14]),\n",
              " array([25, 32, 13, 34, 47, 13, 18, 53, 13,  4, 30,  6, 52, 51,  9, 13, 26,\n",
              "        40, 13, 38,  7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  5, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 41, 13,  4, 30,  6, 52, 51,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([28,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([28,  3, 13, 34, 47, 13, 48, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 41, 13, 28,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([28,  5, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  3, 13, 34, 47, 13, 48, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  9, 13, 42, 13, 25, 32, 53, 13,  2,  3, 33, 40, 13,\n",
              "        38,  7, 35,  2, 14]),\n",
              " array([25, 32, 41, 13, 33, 20, 15, 53,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 13, 34, 47, 13, 18, 41, 13, 33, 20, 15, 53, 13, 34, 47, 13,\n",
              "        48,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53, 13, 34, 47, 13, 48,  5, 13, 25, 32, 53, 13, 38,  7,\n",
              "        35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  5, 13, 33, 20, 15, 53, 13, 34, 47, 13, 48,  3,\n",
              "        13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  5, 13, 33, 20, 15, 53, 13, 34, 47, 13, 48,  3, 13, 38,\n",
              "         7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  5, 13, 24,  4, 22,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  5, 13,  4, 30,  6, 52, 51,  3, 13, 38,  7, 35,  2,\n",
              "        14]),\n",
              " array([ 4, 30,  6, 52, 51,  5, 13, 24,  4, 22,  3, 13, 34, 47, 13, 48, 13,\n",
              "        38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22, 13, 34, 47, 13, 48,  5, 13,  4, 30, 13,  6, 52, 51,  3,\n",
              "        13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 41, 13, 28, 57, 13, 33, 20, 15, 53, 57, 13, 24,  4, 22,  3,\n",
              "        13,  2, 50, 13, 38,  7, 35,  2, 14]),\n",
              " array([28, 57, 13, 33, 20, 15, 53, 57, 13, 24,  4, 22, 57, 13, 25, 32, 53,\n",
              "        13,  2, 50, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22, 57, 13, 25, 32, 57, 13, 33, 20, 15, 53,  3, 13,  2, 50,\n",
              "        13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  5, 13, 24,  4, 22, 57, 13,  4, 30,  6, 52, 51, 13,\n",
              "        34, 47, 13, 48,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([28,  5, 13, 33, 20, 15, 53,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22, 13, 34, 47, 13, 48,  5, 13, 25, 32, 53, 13, 38,  7, 35,\n",
              "         2, 14]),\n",
              " array([33, 20, 15, 53,  9, 13, 42, 13, 25, 32, 53, 13, 34, 55, 13, 38,  7,\n",
              "        35,  2, 14]),\n",
              " array([24,  4, 22, 57, 13, 28, 13, 34, 47, 13, 48,  5, 13, 25, 32, 53, 13,\n",
              "        38,  7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  9, 13, 42, 13, 25, 32, 13, 34, 55, 41, 13,  4,\n",
              "        30,  6, 52, 51, 57, 13, 24,  4, 22,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([44, 23, 51,  3, 13, 17, 37, 13, 10, 11, 13, 38,  7, 35,  2, 14]),\n",
              " array([44, 23, 51,  5, 13, 24,  4, 22,  3, 13, 34, 55, 13, 38,  7, 35,  2,\n",
              "        14]),\n",
              " array([24,  4, 22, 13, 34, 47, 13, 48,  5, 13, 56, 23, 51, 13, 34, 47, 36,\n",
              "         3, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  9, 13, 42, 13, 25, 32, 41, 13, 44, 23, 51, 13, 34,\n",
              "        47, 36,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  9, 13, 42, 13, 25, 32, 41, 13, 33, 20, 15, 53,  9, 13,\n",
              "        42, 13, 25, 32, 53, 13, 34, 55, 13, 38,  7, 35,  2, 14]),\n",
              " array([44, 23, 51, 57, 13, 33, 20, 15, 53, 57, 13,  4, 30,  6, 52, 51,  3,\n",
              "        13, 38,  7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  9, 13, 42, 13, 25, 32, 41, 13, 44, 23, 51,  3,\n",
              "        13, 34, 55, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  9, 13, 42, 13, 25, 32, 41, 13,  4, 30,  6, 52, 51, 57,\n",
              "        13, 44, 23, 51,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 53, 13,  2,  3, 33, 40, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 53, 13, 58, 11,  3, 40, 13, 38,  7, 35,  2, 14]),\n",
              " array([44, 23, 51,  3, 13, 17, 37, 10, 11, 13, 38,  7, 35,  2, 14]),\n",
              " array([24, 30, 28,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  3, 13, 46, 39, 29, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  9, 13, 42, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  3, 13, 19, 34, 13, 38,  7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  9, 13, 42, 13, 25, 32, 53, 13, 38,  7, 35,  2,\n",
              "        14]),\n",
              " array([33, 20, 15, 53,  3, 13, 46, 39, 29, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  9, 13, 42, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([25, 32, 13, 43, 13, 18, 53, 13,  2,  3,  1, 35,  2, 14]),\n",
              " array([25, 32, 54, 53, 13, 34, 55, 13, 38,  7, 35,  2, 14]),\n",
              " array([44, 23, 51,  3, 13, 45, 11, 12, 13, 38,  7, 35,  2, 14]),\n",
              " array([24, 30, 28,  3, 13, 34, 47, 13, 48, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22, 13, 34, 47, 13, 48,  3, 13, 19, 34, 13, 38,  7, 35,  2,\n",
              "        14]),\n",
              " array([24,  4, 22,  9, 13, 42, 13, 25, 32, 53, 13, 31, 13, 38,  7, 35,  2,\n",
              "        14]),\n",
              " array([24,  4, 22,  9, 13, 42, 13, 25, 32, 53, 13, 34, 55, 13, 38,  7, 35,\n",
              "         2, 14]),\n",
              " array([ 4, 30,  6, 52, 51, 13, 43, 13, 48,  3, 13, 19, 34, 13, 38,  7, 35,\n",
              "         2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  3, 13, 34, 47, 13, 48, 13, 19, 34, 13, 38,  7,\n",
              "        35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  9, 13, 42, 13, 25, 32, 53, 13, 31, 13, 38,  7,\n",
              "        35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  9, 13, 42, 13, 25, 32, 53, 13, 34, 55, 13, 38,\n",
              "         7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53, 13, 43, 13, 48,  3, 13, 46, 39, 29, 13, 38,  7, 35,\n",
              "         2, 14]),\n",
              " array([33, 20, 15, 53, 13, 34, 47, 13, 48,  3, 13, 12, 13, 38,  7, 35,  2,\n",
              "        14]),\n",
              " array([33, 20, 15, 53,  9, 13, 42, 13, 25, 32, 53, 13, 34, 55, 13, 38,  7,\n",
              "        35,  2, 14]),\n",
              " array([25, 32, 53, 13,  2,  3, 33, 40, 13, 38, 40, 13, 44, 23, 51,  3, 13,\n",
              "        38,  7, 35,  2, 14]),\n",
              " array([44, 23, 51,  3, 13, 38, 40, 13, 25, 32, 53, 13,  2,  3, 33, 40, 13,\n",
              "        38,  7, 35,  2, 14]),\n",
              " array([44, 23, 51,  5, 13, 24, 30, 28,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([24, 30, 28,  5, 13, 44, 23, 51,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([24, 30, 28,  5, 13, 24,  4, 22,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  5, 13, 24, 30, 28,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  9, 13, 42, 13, 25, 32, 41, 13, 24, 30, 28,  3, 13, 38,\n",
              "         7, 35,  2, 14]),\n",
              " array([24,  4, 22,  5, 13,  4, 30,  6, 52, 51,  3, 13, 19, 34, 13, 38,  7,\n",
              "        35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  5, 13, 24,  4, 22,  3, 13, 19, 34, 13, 38,  7,\n",
              "        35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  5, 13, 33, 20, 15, 53,  3, 13, 19, 34, 13, 38,\n",
              "         7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  5, 13,  4, 30,  6, 52, 51,  3, 13, 19, 34, 13, 38,\n",
              "         7, 35,  2, 14]),\n",
              " array([24,  4, 22,  9, 13, 42, 13, 25, 32, 41, 13, 44, 23, 51,  3, 13, 38,\n",
              "         7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  9, 13, 42, 13, 25, 32, 41, 13, 44, 23, 51,  3,\n",
              "        13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  9, 13, 42, 13, 25, 32, 41, 13, 44, 23, 51,  3, 13,\n",
              "        38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  9, 13, 42, 13, 25, 32, 41, 13,  4, 30,  6, 52, 51,  9,\n",
              "        13, 42, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  9, 13, 42, 13, 25, 32, 41, 13, 24,  4, 22,  9,\n",
              "        13, 42, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  9, 13, 42, 13, 25, 32, 41, 13, 24,  4, 22,  9, 13,\n",
              "        42, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([24,  4, 22,  9, 13, 42, 13, 25, 32, 41, 13, 33, 20, 15, 53,  9, 13,\n",
              "        42, 13, 25, 32, 53, 13, 38,  7, 35,  2, 14]),\n",
              " array([24, 30, 28,  5, 13, 33, 20, 15, 53,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  5, 13, 24, 30, 28,  3, 13, 38,  7, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  3, 13, 19, 34, 13, 38, 40, 13, 25, 32, 53, 13, 58,\n",
              "        11, 16, 35,  2, 14]),\n",
              " array([24,  4, 22,  3, 13, 19, 34, 13, 38, 40, 13, 25, 32, 53, 13, 58, 11,\n",
              "        16, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  3, 13, 19, 34, 13, 38, 40, 13, 25, 32, 53, 13,\n",
              "        58, 11, 16, 35,  2, 14]),\n",
              " array([33, 20, 15, 53,  3, 13, 19, 34, 13, 38, 40, 13, 25, 32, 53, 13,  2,\n",
              "         3,  1, 35,  2, 14]),\n",
              " array([24,  4, 22,  3, 13, 19, 34, 13, 38, 40, 13, 25, 32, 53, 13,  2,  3,\n",
              "         1, 35,  2, 14]),\n",
              " array([ 4, 30,  6, 52, 51,  3, 13, 19, 34, 13, 38, 40, 13, 25, 32, 53, 13,\n",
              "         2,  3,  1, 35,  2, 14])]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence2vec_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak6JY2xRGeo7",
        "outputId": "ebba1c06-224e-447a-e266-75ba523b4cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "사람이 다가오고 있습니다<EOS>"
          ]
        }
      ],
      "source": [
        "# vector 복원\n",
        "for num in sentence2vec_list[0]:\n",
        "  for c, id in char2idx.items():\n",
        "    if id == num:\n",
        "      print(c, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "H7Es6J949m4H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "sentence2vec = np.array(sentence2vec_list, dtype=object)\n",
        "\n",
        "sequence_list = []\n",
        "for vec in sentence2vec:\n",
        "    for i in range(len(vec)):\n",
        "        sequence = vec[:i+1]\n",
        "        sequence_list.append(sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioNgQx7p-fN3",
        "outputId": "2744c43d-1691-48ef-f273-ed98b4f80013"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([25]),\n",
              " array([25, 32]),\n",
              " array([25, 32, 53]),\n",
              " array([25, 32, 53, 13]),\n",
              " array([25, 32, 53, 13,  2]),\n",
              " array([25, 32, 53, 13,  2,  3]),\n",
              " array([25, 32, 53, 13,  2,  3, 33]),\n",
              " array([25, 32, 53, 13,  2,  3, 33, 40]),\n",
              " array([25, 32, 53, 13,  2,  3, 33, 40, 13]),\n",
              " array([25, 32, 53, 13,  2,  3, 33, 40, 13, 38]),\n",
              " array([25, 32, 53, 13,  2,  3, 33, 40, 13, 38,  7]),\n",
              " array([25, 32, 53, 13,  2,  3, 33, 40, 13, 38,  7, 35]),\n",
              " array([25, 32, 53, 13,  2,  3, 33, 40, 13, 38,  7, 35,  2]),\n",
              " array([25, 32, 53, 13,  2,  3, 33, 40, 13, 38,  7, 35,  2, 14]),\n",
              " array([25])]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence_list[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "3nGG-HIR_T11",
        "outputId": "004cf713-84c1-46f7-b317-39afb37660a2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist([len(s) for s in sentence2vec_list], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gLJA50vr_9I3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = max(map(len, sentence2vec_list))\n",
        "sequences = pad_sequences(sequence_list, maxlen=max_len, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UACXWsOPBTn2",
        "outputId": "2216f42f-c373-44d3-bc6d-919db1475a33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 22],\n",
              "      dtype=int32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "H1OXg0IwBqUt"
      },
      "outputs": [],
      "source": [
        "np.random.shuffle(sequences)\n",
        "split_num = int(len(sequences) * 0.8)\n",
        "\n",
        "X = sequences[:split_num,:-1]\n",
        "y = sequences[:split_num,-1]\n",
        "\n",
        "X_test = sequences[split_num:,:-1]\n",
        "y_test = sequences[split_num:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xe6WUSPCD5F",
        "outputId": "edbc36d8-face-4d2c-d380-4fabce9498a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 32, 300)           1500000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               165120    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5000)              645000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,310,120\n",
            "Trainable params: 2,310,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "47/47 [==============================] - 15s 194ms/step - loss: 6.3629 - accuracy: 0.2281 - val_loss: 3.8629 - val_accuracy: 0.1677\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 15s 314ms/step - loss: 3.6740 - accuracy: 0.1887 - val_loss: 3.6788 - val_accuracy: 0.1806\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 11s 243ms/step - loss: 3.5269 - accuracy: 0.1923 - val_loss: 3.5760 - val_accuracy: 0.1806\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 3.4487 - accuracy: 0.1923 - val_loss: 3.5010 - val_accuracy: 0.1806\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 3.3736 - accuracy: 0.2195 - val_loss: 3.4252 - val_accuracy: 0.1806\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 3.2780 - accuracy: 0.2389 - val_loss: 3.2973 - val_accuracy: 0.2323\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 3.1103 - accuracy: 0.2991 - val_loss: 3.0818 - val_accuracy: 0.3355\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 2.8933 - accuracy: 0.3831 - val_loss: 2.8730 - val_accuracy: 0.3935\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 2.6646 - accuracy: 0.4125 - val_loss: 2.6367 - val_accuracy: 0.4000\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 2.3975 - accuracy: 0.4778 - val_loss: 2.3771 - val_accuracy: 0.5419\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 2.1279 - accuracy: 0.5689 - val_loss: 2.1442 - val_accuracy: 0.6323\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 1.9025 - accuracy: 0.6370 - val_loss: 1.9290 - val_accuracy: 0.6452\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 1.7096 - accuracy: 0.6714 - val_loss: 1.7765 - val_accuracy: 0.6839\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 1.5518 - accuracy: 0.6872 - val_loss: 1.6369 - val_accuracy: 0.6968\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 1.4330 - accuracy: 0.7209 - val_loss: 1.5391 - val_accuracy: 0.7032\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 1.3266 - accuracy: 0.7403 - val_loss: 1.4681 - val_accuracy: 0.7032\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 1.2530 - accuracy: 0.7511 - val_loss: 1.4046 - val_accuracy: 0.7161\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 1.1896 - accuracy: 0.7618 - val_loss: 1.3715 - val_accuracy: 0.7290\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 1.1402 - accuracy: 0.7719 - val_loss: 1.2995 - val_accuracy: 0.7226\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 1.1005 - accuracy: 0.7704 - val_loss: 1.2609 - val_accuracy: 0.7484\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 1.0589 - accuracy: 0.7855 - val_loss: 1.2272 - val_accuracy: 0.7419\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 1.0247 - accuracy: 0.7891 - val_loss: 1.1981 - val_accuracy: 0.7548\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 1.0014 - accuracy: 0.8049 - val_loss: 1.1573 - val_accuracy: 0.7871\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.9697 - accuracy: 0.8020 - val_loss: 1.1397 - val_accuracy: 0.7871\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 7s 159ms/step - loss: 0.9443 - accuracy: 0.8099 - val_loss: 1.1153 - val_accuracy: 0.7871\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.9143 - accuracy: 0.8142 - val_loss: 1.0937 - val_accuracy: 0.7742\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.8849 - accuracy: 0.8171 - val_loss: 1.0503 - val_accuracy: 0.8065\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.8631 - accuracy: 0.8192 - val_loss: 1.0449 - val_accuracy: 0.7935\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.8391 - accuracy: 0.8221 - val_loss: 1.0444 - val_accuracy: 0.7871\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.8198 - accuracy: 0.8214 - val_loss: 0.9998 - val_accuracy: 0.8065\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.7982 - accuracy: 0.8235 - val_loss: 0.9869 - val_accuracy: 0.8129\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.7820 - accuracy: 0.8307 - val_loss: 0.9811 - val_accuracy: 0.8129\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.7660 - accuracy: 0.8329 - val_loss: 0.9633 - val_accuracy: 0.7871\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.7524 - accuracy: 0.8307 - val_loss: 0.9605 - val_accuracy: 0.8129\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.7461 - accuracy: 0.8314 - val_loss: 0.9449 - val_accuracy: 0.8194\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.7311 - accuracy: 0.8336 - val_loss: 0.9523 - val_accuracy: 0.7935\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.7232 - accuracy: 0.8364 - val_loss: 0.9389 - val_accuracy: 0.8258\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.7107 - accuracy: 0.8393 - val_loss: 0.9174 - val_accuracy: 0.8194\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.7012 - accuracy: 0.8429 - val_loss: 0.9216 - val_accuracy: 0.8194\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.6942 - accuracy: 0.8357 - val_loss: 0.9229 - val_accuracy: 0.8129\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.6851 - accuracy: 0.8400 - val_loss: 0.9125 - val_accuracy: 0.8194\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 8s 169ms/step - loss: 0.6800 - accuracy: 0.8479 - val_loss: 0.9023 - val_accuracy: 0.8452\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.6701 - accuracy: 0.8458 - val_loss: 0.9250 - val_accuracy: 0.8129\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.6651 - accuracy: 0.8522 - val_loss: 0.9179 - val_accuracy: 0.8129\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.6582 - accuracy: 0.8465 - val_loss: 0.9263 - val_accuracy: 0.8129\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 0.6513 - accuracy: 0.8537 - val_loss: 0.9151 - val_accuracy: 0.8387\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.6501 - accuracy: 0.8479 - val_loss: 0.9002 - val_accuracy: 0.8387\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.6433 - accuracy: 0.8451 - val_loss: 0.9112 - val_accuracy: 0.8065\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.6357 - accuracy: 0.8558 - val_loss: 0.9121 - val_accuracy: 0.8387\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.6324 - accuracy: 0.8515 - val_loss: 0.9150 - val_accuracy: 0.8323\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.6247 - accuracy: 0.8522 - val_loss: 0.9348 - val_accuracy: 0.8000\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 8s 160ms/step - loss: 0.6188 - accuracy: 0.8494 - val_loss: 0.9085 - val_accuracy: 0.8323\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.6164 - accuracy: 0.8508 - val_loss: 0.9211 - val_accuracy: 0.8000\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.6133 - accuracy: 0.8508 - val_loss: 0.9214 - val_accuracy: 0.8129\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 8s 160ms/step - loss: 0.6109 - accuracy: 0.8508 - val_loss: 0.9229 - val_accuracy: 0.7935\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 8s 160ms/step - loss: 0.5991 - accuracy: 0.8580 - val_loss: 0.9117 - val_accuracy: 0.8194\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.5958 - accuracy: 0.8508 - val_loss: 0.9473 - val_accuracy: 0.7935\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.5920 - accuracy: 0.8486 - val_loss: 0.9290 - val_accuracy: 0.7935\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.5869 - accuracy: 0.8522 - val_loss: 0.9181 - val_accuracy: 0.7935\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.5803 - accuracy: 0.8551 - val_loss: 0.9071 - val_accuracy: 0.8323\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.5750 - accuracy: 0.8587 - val_loss: 0.9201 - val_accuracy: 0.7871\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.5780 - accuracy: 0.8522 - val_loss: 0.9099 - val_accuracy: 0.8000\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.5709 - accuracy: 0.8529 - val_loss: 0.9067 - val_accuracy: 0.8258\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.5648 - accuracy: 0.8580 - val_loss: 0.9176 - val_accuracy: 0.7935\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.5631 - accuracy: 0.8522 - val_loss: 0.9019 - val_accuracy: 0.8258\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.5653 - accuracy: 0.8537 - val_loss: 0.9328 - val_accuracy: 0.8194\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.5549 - accuracy: 0.8522 - val_loss: 0.9150 - val_accuracy: 0.8065\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.5517 - accuracy: 0.8551 - val_loss: 0.9122 - val_accuracy: 0.8129\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.5477 - accuracy: 0.8537 - val_loss: 0.9185 - val_accuracy: 0.8194\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.5423 - accuracy: 0.8608 - val_loss: 0.9094 - val_accuracy: 0.8387\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.5377 - accuracy: 0.8594 - val_loss: 0.8798 - val_accuracy: 0.8323\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.5343 - accuracy: 0.8651 - val_loss: 0.9185 - val_accuracy: 0.7935\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.5328 - accuracy: 0.8651 - val_loss: 0.9129 - val_accuracy: 0.8387\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.5260 - accuracy: 0.8587 - val_loss: 0.9165 - val_accuracy: 0.8000\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.5195 - accuracy: 0.8587 - val_loss: 0.9032 - val_accuracy: 0.8129\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 7s 159ms/step - loss: 0.5218 - accuracy: 0.8587 - val_loss: 0.8986 - val_accuracy: 0.7935\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.5191 - accuracy: 0.8608 - val_loss: 0.8903 - val_accuracy: 0.8000\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.5091 - accuracy: 0.8637 - val_loss: 0.9072 - val_accuracy: 0.8194\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.5055 - accuracy: 0.8637 - val_loss: 0.9114 - val_accuracy: 0.7935\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 0.5004 - accuracy: 0.8615 - val_loss: 0.9067 - val_accuracy: 0.8323\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.4978 - accuracy: 0.8673 - val_loss: 0.9000 - val_accuracy: 0.8323\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.4935 - accuracy: 0.8565 - val_loss: 0.8995 - val_accuracy: 0.8258\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.4870 - accuracy: 0.8666 - val_loss: 0.9047 - val_accuracy: 0.8323\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.4839 - accuracy: 0.8594 - val_loss: 0.9057 - val_accuracy: 0.8387\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.4774 - accuracy: 0.8630 - val_loss: 0.8804 - val_accuracy: 0.8323\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.4741 - accuracy: 0.8687 - val_loss: 0.9129 - val_accuracy: 0.7806\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.4720 - accuracy: 0.8608 - val_loss: 0.8966 - val_accuracy: 0.8387\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.4667 - accuracy: 0.8687 - val_loss: 0.9056 - val_accuracy: 0.8323\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.4639 - accuracy: 0.8716 - val_loss: 0.8843 - val_accuracy: 0.8323\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.4612 - accuracy: 0.8659 - val_loss: 0.8761 - val_accuracy: 0.8258\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.4553 - accuracy: 0.8702 - val_loss: 0.8830 - val_accuracy: 0.7935\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.4536 - accuracy: 0.8673 - val_loss: 0.8727 - val_accuracy: 0.8065\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.4468 - accuracy: 0.8666 - val_loss: 0.8938 - val_accuracy: 0.8065\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 8s 160ms/step - loss: 0.4429 - accuracy: 0.8766 - val_loss: 0.8967 - val_accuracy: 0.8258\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.4397 - accuracy: 0.8766 - val_loss: 0.8923 - val_accuracy: 0.8258\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.4354 - accuracy: 0.8730 - val_loss: 0.8944 - val_accuracy: 0.7935\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.4298 - accuracy: 0.8766 - val_loss: 0.8865 - val_accuracy: 0.8258\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.4293 - accuracy: 0.8766 - val_loss: 0.9109 - val_accuracy: 0.8000\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 7s 159ms/step - loss: 0.4257 - accuracy: 0.8737 - val_loss: 0.8903 - val_accuracy: 0.8258\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 0.4204 - accuracy: 0.8759 - val_loss: 0.8817 - val_accuracy: 0.8065\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.4225 - accuracy: 0.8745 - val_loss: 0.8879 - val_accuracy: 0.8000\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.4155 - accuracy: 0.8745 - val_loss: 0.9081 - val_accuracy: 0.7806\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.4109 - accuracy: 0.8766 - val_loss: 0.9016 - val_accuracy: 0.8065\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.4095 - accuracy: 0.8759 - val_loss: 0.8910 - val_accuracy: 0.8258\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.4062 - accuracy: 0.8773 - val_loss: 0.9139 - val_accuracy: 0.7742\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.4000 - accuracy: 0.8795 - val_loss: 0.9060 - val_accuracy: 0.8065\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.4000 - accuracy: 0.8780 - val_loss: 0.9291 - val_accuracy: 0.7806\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.3968 - accuracy: 0.8745 - val_loss: 0.9189 - val_accuracy: 0.8000\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3918 - accuracy: 0.8780 - val_loss: 0.9189 - val_accuracy: 0.7935\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.3883 - accuracy: 0.8737 - val_loss: 0.9255 - val_accuracy: 0.7935\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.3867 - accuracy: 0.8745 - val_loss: 0.9131 - val_accuracy: 0.7806\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.3847 - accuracy: 0.8766 - val_loss: 0.9153 - val_accuracy: 0.8258\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.3822 - accuracy: 0.8773 - val_loss: 0.9166 - val_accuracy: 0.7871\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3785 - accuracy: 0.8773 - val_loss: 0.9409 - val_accuracy: 0.8194\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.3842 - accuracy: 0.8773 - val_loss: 0.9025 - val_accuracy: 0.8194\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3801 - accuracy: 0.8730 - val_loss: 0.9269 - val_accuracy: 0.8065\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3762 - accuracy: 0.8773 - val_loss: 0.9259 - val_accuracy: 0.7935\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.3705 - accuracy: 0.8780 - val_loss: 0.9297 - val_accuracy: 0.7806\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.3670 - accuracy: 0.8752 - val_loss: 0.9355 - val_accuracy: 0.7935\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 8s 160ms/step - loss: 0.3655 - accuracy: 0.8809 - val_loss: 0.9089 - val_accuracy: 0.8065\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3620 - accuracy: 0.8759 - val_loss: 0.9057 - val_accuracy: 0.8323\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.3657 - accuracy: 0.8780 - val_loss: 0.9657 - val_accuracy: 0.7871\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.3611 - accuracy: 0.8766 - val_loss: 0.9231 - val_accuracy: 0.7871\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.3636 - accuracy: 0.8809 - val_loss: 0.9082 - val_accuracy: 0.8258\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3542 - accuracy: 0.8802 - val_loss: 0.9521 - val_accuracy: 0.8129\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.3522 - accuracy: 0.8780 - val_loss: 0.9414 - val_accuracy: 0.8258\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3474 - accuracy: 0.8780 - val_loss: 0.9438 - val_accuracy: 0.7935\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.3466 - accuracy: 0.8773 - val_loss: 0.9301 - val_accuracy: 0.8000\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.3424 - accuracy: 0.8816 - val_loss: 0.9440 - val_accuracy: 0.7871\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.3430 - accuracy: 0.8766 - val_loss: 0.9255 - val_accuracy: 0.8129\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.3399 - accuracy: 0.8773 - val_loss: 0.9363 - val_accuracy: 0.7806\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.3354 - accuracy: 0.8809 - val_loss: 0.9471 - val_accuracy: 0.7935\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.3352 - accuracy: 0.8766 - val_loss: 0.9465 - val_accuracy: 0.7871\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 7s 159ms/step - loss: 0.3326 - accuracy: 0.8816 - val_loss: 0.9374 - val_accuracy: 0.8258\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.3343 - accuracy: 0.8766 - val_loss: 0.9272 - val_accuracy: 0.8129\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.3307 - accuracy: 0.8759 - val_loss: 0.9277 - val_accuracy: 0.8258\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 7s 159ms/step - loss: 0.3299 - accuracy: 0.8745 - val_loss: 0.9548 - val_accuracy: 0.8258\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.3249 - accuracy: 0.8788 - val_loss: 0.9427 - val_accuracy: 0.8065\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.3213 - accuracy: 0.8795 - val_loss: 0.9566 - val_accuracy: 0.7871\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 8s 169ms/step - loss: 0.3204 - accuracy: 0.8795 - val_loss: 0.9517 - val_accuracy: 0.7871\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3190 - accuracy: 0.8773 - val_loss: 0.9509 - val_accuracy: 0.7871\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3181 - accuracy: 0.8816 - val_loss: 0.9400 - val_accuracy: 0.8000\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3171 - accuracy: 0.8780 - val_loss: 0.9657 - val_accuracy: 0.7935\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.3161 - accuracy: 0.8838 - val_loss: 0.9656 - val_accuracy: 0.8258\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.3134 - accuracy: 0.8795 - val_loss: 0.9551 - val_accuracy: 0.8065\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.3124 - accuracy: 0.8780 - val_loss: 0.9452 - val_accuracy: 0.8065\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.3101 - accuracy: 0.8816 - val_loss: 0.9575 - val_accuracy: 0.7871\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.3074 - accuracy: 0.8766 - val_loss: 0.9606 - val_accuracy: 0.7806\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 0.3060 - accuracy: 0.8867 - val_loss: 0.9534 - val_accuracy: 0.8065\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.3052 - accuracy: 0.8824 - val_loss: 0.9712 - val_accuracy: 0.7742\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.3048 - accuracy: 0.8809 - val_loss: 0.9670 - val_accuracy: 0.8129\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.3027 - accuracy: 0.8816 - val_loss: 0.9639 - val_accuracy: 0.7742\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 0.3044 - accuracy: 0.8802 - val_loss: 0.9659 - val_accuracy: 0.7871\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.3034 - accuracy: 0.8809 - val_loss: 0.9603 - val_accuracy: 0.7806\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.2978 - accuracy: 0.8795 - val_loss: 0.9637 - val_accuracy: 0.8000\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 8s 160ms/step - loss: 0.2995 - accuracy: 0.8816 - val_loss: 0.9612 - val_accuracy: 0.8065\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.2963 - accuracy: 0.8816 - val_loss: 0.9706 - val_accuracy: 0.8065\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.2943 - accuracy: 0.8824 - val_loss: 0.9911 - val_accuracy: 0.7677\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.2950 - accuracy: 0.8795 - val_loss: 0.9665 - val_accuracy: 0.7806\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.2926 - accuracy: 0.8809 - val_loss: 0.9712 - val_accuracy: 0.8000\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.2917 - accuracy: 0.8809 - val_loss: 0.9739 - val_accuracy: 0.7871\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.2908 - accuracy: 0.8809 - val_loss: 0.9901 - val_accuracy: 0.7806\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.2894 - accuracy: 0.8824 - val_loss: 0.9739 - val_accuracy: 0.8000\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.2893 - accuracy: 0.8788 - val_loss: 0.9888 - val_accuracy: 0.7742\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.2863 - accuracy: 0.8824 - val_loss: 0.9914 - val_accuracy: 0.8129\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.2863 - accuracy: 0.8824 - val_loss: 0.9977 - val_accuracy: 0.7742\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.2848 - accuracy: 0.8831 - val_loss: 1.0055 - val_accuracy: 0.7935\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 7s 160ms/step - loss: 0.2833 - accuracy: 0.8824 - val_loss: 0.9969 - val_accuracy: 0.7806\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.2816 - accuracy: 0.8824 - val_loss: 0.9961 - val_accuracy: 0.8129\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 0.2808 - accuracy: 0.8838 - val_loss: 1.0083 - val_accuracy: 0.7806\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 8s 168ms/step - loss: 0.2823 - accuracy: 0.8780 - val_loss: 1.0003 - val_accuracy: 0.8000\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.2791 - accuracy: 0.8816 - val_loss: 1.0066 - val_accuracy: 0.7871\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.2796 - accuracy: 0.8824 - val_loss: 0.9823 - val_accuracy: 0.8129\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.2789 - accuracy: 0.8845 - val_loss: 1.0130 - val_accuracy: 0.7806\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.2809 - accuracy: 0.8788 - val_loss: 0.9315 - val_accuracy: 0.7935\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 8s 160ms/step - loss: 0.2907 - accuracy: 0.8795 - val_loss: 0.9698 - val_accuracy: 0.7742\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.3012 - accuracy: 0.8737 - val_loss: 0.9097 - val_accuracy: 0.7806\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.2971 - accuracy: 0.8802 - val_loss: 0.8697 - val_accuracy: 0.8258\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.3010 - accuracy: 0.8788 - val_loss: 0.8634 - val_accuracy: 0.7935\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.2875 - accuracy: 0.8852 - val_loss: 0.8978 - val_accuracy: 0.7935\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 7s 159ms/step - loss: 0.2836 - accuracy: 0.8773 - val_loss: 0.8833 - val_accuracy: 0.8194\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.2785 - accuracy: 0.8852 - val_loss: 0.9049 - val_accuracy: 0.7935\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 8s 166ms/step - loss: 0.2774 - accuracy: 0.8838 - val_loss: 0.9037 - val_accuracy: 0.8129\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.2747 - accuracy: 0.8824 - val_loss: 0.9219 - val_accuracy: 0.8258\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 8s 160ms/step - loss: 0.2741 - accuracy: 0.8824 - val_loss: 0.9328 - val_accuracy: 0.8258\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 7s 158ms/step - loss: 0.2714 - accuracy: 0.8824 - val_loss: 0.9326 - val_accuracy: 0.8000\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.2708 - accuracy: 0.8824 - val_loss: 0.9050 - val_accuracy: 0.8129\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.2722 - accuracy: 0.8824 - val_loss: 0.9389 - val_accuracy: 0.8258\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.2675 - accuracy: 0.8809 - val_loss: 0.9327 - val_accuracy: 0.8000\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.2704 - accuracy: 0.8824 - val_loss: 0.9339 - val_accuracy: 0.8065\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 8s 161ms/step - loss: 0.2708 - accuracy: 0.8867 - val_loss: 0.9506 - val_accuracy: 0.8000\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.2695 - accuracy: 0.8824 - val_loss: 0.9390 - val_accuracy: 0.8323\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.2678 - accuracy: 0.8824 - val_loss: 0.9569 - val_accuracy: 0.8065\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 8s 163ms/step - loss: 0.2653 - accuracy: 0.8852 - val_loss: 0.9609 - val_accuracy: 0.8258\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 8s 165ms/step - loss: 0.2663 - accuracy: 0.8824 - val_loss: 0.9665 - val_accuracy: 0.8000\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.2643 - accuracy: 0.8809 - val_loss: 0.9506 - val_accuracy: 0.8065\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 8s 167ms/step - loss: 0.2636 - accuracy: 0.8859 - val_loss: 0.9605 - val_accuracy: 0.8258\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 8s 162ms/step - loss: 0.2650 - accuracy: 0.8859 - val_loss: 0.9583 - val_accuracy: 0.8258\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 8s 160ms/step - loss: 0.2626 - accuracy: 0.8852 - val_loss: 0.9748 - val_accuracy: 0.7935\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 8s 164ms/step - loss: 0.2628 - accuracy: 0.8881 - val_loss: 0.9691 - val_accuracy: 0.8065\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, GRU\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# early_stopping = EarlyStopping() \n",
        "# 조기종료 : epoch를 길게 돌리지 않고, 이전 epoch보다 accuracy가 낮을 경우 종료\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, 300, input_length=max_len-1, mask_zero=True)) \n",
        "# 레이블을 분리하였으므로 이제 X의 길이는 max_len-1\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(5000, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# sparse_categorical_crossentropy\n",
        "# categorical_crossentropy와 다른점은 정답 integer값을 원-핫벡터로 만들어주지 않아도 된다는점\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# hist = model.fit(X, y,validation_split=0.1,shuffle=True, epochs=100, batch_size=30, verbose=1, callbacks=[early_stopping])\n",
        "hist = model.fit(X, y,validation_split=0.1, shuffle=True, epochs=200, batch_size=30, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "WTcXpJLJf6dN",
        "outputId": "89ebac41-1a69-4581-d3ae-3b76d1814af0"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<svg height=\"274pt\" viewBox=\"0.00 0.00 354.00 304.00\" width=\"320pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.9028 .9028) rotate(0) translate(4 300)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-300 350,-300 350,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139830386076176 -->\n<g class=\"node\" id=\"node1\">\n<title>139830386076176</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 346,-295.5 346,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"59.5\" y=\"-268.8\">embedding_input</text>\n<polyline fill=\"none\" points=\"119,-249.5 119,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-268.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"199,-249.5 199,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"199,-272.5 257,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"257,-249.5 257,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.5\" y=\"-280.3\">[(None, 32)]</text>\n<polyline fill=\"none\" points=\"257,-272.5 346,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.5\" y=\"-257.3\">[(None, 32)]</text>\n</g>\n<!-- 139830386458384 -->\n<g class=\"node\" id=\"node2\">\n<title>139830386458384</title>\n<polygon fill=\"none\" points=\"6.5,-166.5 6.5,-212.5 339.5,-212.5 339.5,-166.5 6.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"47\" y=\"-185.8\">embedding</text>\n<polyline fill=\"none\" points=\"87.5,-166.5 87.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129.5\" y=\"-185.8\">Embedding</text>\n<polyline fill=\"none\" points=\"171.5,-166.5 171.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"171.5,-189.5 229.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"229.5,-166.5 229.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-197.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"229.5,-189.5 339.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-174.3\">(None, 32, 300)</text>\n</g>\n<!-- 139830386076176&#45;&gt;139830386458384 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139830386076176-&gt;139830386458384</title>\n<path d=\"M173,-249.3799C173,-241.1745 173,-231.7679 173,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"176.5001,-222.784 173,-212.784 169.5001,-222.784 176.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139830386429392 -->\n<g class=\"node\" id=\"node3\">\n<title>139830386429392</title>\n<polygon fill=\"none\" points=\"47.5,-83.5 47.5,-129.5 298.5,-129.5 298.5,-83.5 47.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-102.8\">gru</text>\n<polyline fill=\"none\" points=\"83.5,-83.5 83.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107\" y=\"-102.8\">GRU</text>\n<polyline fill=\"none\" points=\"130.5,-83.5 130.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"130.5,-106.5 188.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"188.5,-83.5 188.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-114.3\">(None, 32, 300)</text>\n<polyline fill=\"none\" points=\"188.5,-106.5 298.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-91.3\">(None, 128)</text>\n</g>\n<!-- 139830386458384&#45;&gt;139830386429392 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139830386458384-&gt;139830386429392</title>\n<path d=\"M173,-166.3799C173,-158.1745 173,-148.7679 173,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"176.5001,-139.784 173,-129.784 169.5001,-139.784 176.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139830386457168 -->\n<g class=\"node\" id=\"node4\">\n<title>139830386457168</title>\n<polygon fill=\"none\" points=\"46,-.5 46,-46.5 300,-46.5 300,-.5 46,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70.5\" y=\"-19.8\">dense</text>\n<polyline fill=\"none\" points=\"95,-.5 95,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121\" y=\"-19.8\">Dense</text>\n<polyline fill=\"none\" points=\"147,-.5 147,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"147,-23.5 205,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"205,-.5 205,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252.5\" y=\"-31.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"205,-23.5 300,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252.5\" y=\"-8.3\">(None, 5000)</text>\n</g>\n<!-- 139830386429392&#45;&gt;139830386457168 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139830386429392-&gt;139830386457168</title>\n<path d=\"M173,-83.3799C173,-75.1745 173,-65.7679 173,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"176.5001,-56.784 173,-46.784 169.5001,-56.784 176.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>",
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=65).create(prog='dot', format='svg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "AXy02lZLDJB3",
        "outputId": "db73c5ec-f7f6-4d26-c019-a5428e1a46b3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVEUJNcgF5v8",
        "outputId": "cd39a23c-fd2f-4116-fcb1-bfd179431f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 25ms/step - loss: 0.9439 - accuracy: 0.7938\n",
            "\n",
            "loss : 0.9439195394515991\n",
            "accuray : 0.7938144207000732\n"
          ]
        }
      ],
      "source": [
        "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=32)\n",
        "\n",
        "print('')\n",
        "print('loss : ' + str(loss_and_metrics[0]))\n",
        "print('accuray : ' + str(loss_and_metrics[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AblqWiyVGLsQ",
        "outputId": "7323c40a-43bb-4d00-d21b-8ceee16b2221"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'사람이 다가오고 있습니다'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_word = '사람'\n",
        "init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
        "sentence = ''\n",
        "n = 35\n",
        "for _ in range(n): # n번 반복\n",
        "    encoded = [char2idx[token] for token in current_word]#t.texts_to_sequences([current_word])[0] \n",
        "    # 현재 단어에 대한 정수 인코딩\n",
        "    \n",
        "    encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre') \n",
        "    # 데이터에 대한 패딩\n",
        "    \n",
        "    result = np.argmax(model.predict(encoded), axis=-1) \n",
        "\t\n",
        "    # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "    for word, index in char2idx.items(): \n",
        "        if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "            break # 해당 단어가 예측 단어이므로 break\n",
        "    current_word = current_word + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    sentence = sentence + word # 예측 단어를 문장에 저장\n",
        "    if word == '<EOS>':\n",
        "        break\n",
        "# for문이므로 이 행동을 다시 반복\n",
        "sentence = init_word + sentence\n",
        "sentence.replace('<EOS>',\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GFDb6XF1GeHN"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model.save('senten_generating_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyjEWuWo8hhP"
      },
      "source": [
        "모델 불러와 사용해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_8eh5fcdoAav"
      },
      "outputs": [],
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/senten_generating_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Yuz0YBB58s2g",
        "outputId": "85a9bfe0-afa0-449e-bdfe-ac029ff8253c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'사람동으킥 워폴,어,어,거토자,앞둘,걸탄되놓치놓치져되놓치놓치져되놓치'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_word = '사람'\n",
        "init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
        "sentence = ''\n",
        "n = 35\n",
        "for _ in range(n): # n번 반복\n",
        "    encoded = [char2idx[token] for token in current_word]#t.texts_to_sequences([current_word])[0] \n",
        "    # 현재 단어에 대한 정수 인코딩\n",
        "    \n",
        "    encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre') \n",
        "    # 데이터에 대한 패딩\n",
        "    \n",
        "    result = np.argmax(model.predict(encoded), axis=-1) \n",
        "\t\n",
        "    # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "    for word, index in char2idx.items(): \n",
        "        if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "            break # 해당 단어가 예측 단어이므로 break\n",
        "    current_word = current_word + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    sentence = sentence + word # 예측 단어를 문장에 저장\n",
        "    if word == '<EOS>':\n",
        "        break;\n",
        "# for문이므로 이 행동을 다시 반복\n",
        "sentence = init_word + sentence\n",
        "sentence.replace('<EOS>',\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Jv6euZpP-Qbo",
        "outputId": "dab78045-0515-479d-cc23-a47ae18b170d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'사람이동으킥킥킥  워킥킥 워킥있동다가,거토자,걸탄되놓치놓치갑고개자,걸'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_word = '사람이'\n",
        "init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
        "sentence = ''\n",
        "n = 35\n",
        "for _ in range(n): # n번 반복\n",
        "    encoded = [char2idx[token] for token in current_word]#t.texts_to_sequences([current_word])[0] \n",
        "    # 현재 단어에 대한 정수 인코딩\n",
        "    \n",
        "    encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre') \n",
        "    # 데이터에 대한 패딩\n",
        "    \n",
        "    result = np.argmax(model.predict(encoded), axis=-1) \n",
        "\t\n",
        "    # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "    for word, index in char2idx.items(): \n",
        "        if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "            break # 해당 단어가 예측 단어이므로 break\n",
        "    current_word = current_word + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    sentence = sentence + word # 예측 단어를 문장에 저장\n",
        "    if word == '<EOS>':\n",
        "        break;\n",
        "# for문이므로 이 행동을 다시 반복\n",
        "sentence = init_word + sentence\n",
        "sentence.replace('<EOS>',\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGbJVMe1-9l-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sentenceGenerate.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
